{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77833fa9-d4ec-4773-b284-cfea9c54f24d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Dolly Server set-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d140422-e92b-4518-86b1-931c8903baa3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Installing required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "948542e0-b94e-4fa7-8172-98332037aaa8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U chromadb==0.3.22 langchain==0.0.164 transformers==4.29.0 accelerate==0.19.0 bitsandbytes pypdf uvicorn starlette ffmpeg-python ffmpy ffprobe python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3d2fd0-0eef-4ba9-89cb-0a3f18685ab2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e647af53-4601-4ccc-84e3-066bb7683890",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!apt-get install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a382248-f305-4a75-a3d4-c0cc730b4b59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe7a4a60-becb-43eb-865a-fc38bf4e9ecc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Writing Dolly Server code\n",
    "\n",
    "This section creates the server.py file which needs to be run on the Databricks cluster using AWS. We strongly recommend using AWS g5.4xlarge instance on databricks for the Dolly model to function effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8daa3b28-5854-4e3d-900f-b661e4a102c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile server.py\n",
    "import whisper\n",
    "import re, time\n",
    "from io import BytesIO\n",
    "from typing import Any, Dict, List\n",
    "from pypdf import PdfReader\n",
    "import magic\n",
    "import shutil\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch, asyncio, os\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from starlette.applications import Starlette\n",
    "from starlette.responses import JSONResponse\n",
    "from starlette.routing import Route\n",
    "\n",
    "PDF_DIRECTORY = \"/dbfs/data\"\n",
    "\n",
    "vector_db_path = \"./vector_db\"\n",
    "\n",
    "model_whisper = whisper.load_model(\"medium\")\n",
    "\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def clear_files(directory):\n",
    "    \"\"\"\n",
    "    Clears out all files and subdirectories in the specified directory.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory):\n",
    "        try:\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    os.remove(file_path)\n",
    "\n",
    "                for dir in dirs:\n",
    "                    dir_path = os.path.join(root, dir)\n",
    "                    shutil.rmtree(dir_path)\n",
    "            print(\"Previous embeddings deleted\")\n",
    "\n",
    "        except OSError as e:\n",
    "            print(f\"Error while clearing files: {e}\")\n",
    "    else:\n",
    "        print(\"Directory does not exist.\")\n",
    "\n",
    "\n",
    "def parse_pdf(file: BytesIO) -> List[str]:\n",
    "    \"\"\"Parse the content of a PDF file and extract the text from each page.\n",
    "    Args:\n",
    "        file (BytesIO): A file-like object containing the PDF data.\n",
    "    Returns:\n",
    "        List[str]: A list of extracted text from each page of the PDF.\n",
    "    \"\"\"\n",
    "    pdf = PdfReader(file)\n",
    "    output = []\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        # Merge hyphenated words\n",
    "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "        # Fix newlines in the middle of sentences\n",
    "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
    "        # Remove multiple newlines\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "def multimedia_to_text(path):\n",
    "    \"\"\"Transcribe audio or video file to text using the model_whisper library.\n",
    "    Args:\n",
    "        path (str): The path to the file. Can be MP3,WAV, MP4\n",
    "    Returns:\n",
    "        str: The transcribed text from the audio.\n",
    "    \"\"\"    \n",
    "    text = model_whisper.transcribe(path)\n",
    "    #printing the transcribe\n",
    "    return text['text']\n",
    "\n",
    "def text_to_docs(text: str) -> List[Document]:\n",
    "    \"\"\"Converts a string or list of strings to a list of Documents\n",
    "    with metadata.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Take a single string as one page\n",
    "        text = [text]\n",
    "    page_docs = [Document(page_content=page) for page in text]\n",
    "\n",
    "    # Add page numbers as metadata\n",
    "    for i, doc in enumerate(page_docs):\n",
    "        doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "    # Split pages into chunks\n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in page_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
    "            )\n",
    "            # Add sources a metadata\n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc_chunks.append(doc)\n",
    "    return doc_chunks\n",
    "\n",
    "\n",
    "def create_embed(pages) :\n",
    "    \"\"\"Create embeddings for a list of pages and persist them using Chroma.\n",
    "    Args:\n",
    "        pages (List[str]): A list of pages to create embeddings for.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    global db\n",
    "    db = Chroma.from_documents(documents=pages, embedding_function=hf_embed, persist_directory=vector_db_path)\n",
    "    db.similarity_search(\"dummy\") # tickle it to persist metadata (?)\n",
    "    db.persist()\n",
    "\n",
    "def get_similar_docs(question, similar_doc_count):\n",
    "    # db = Chroma(embedding_function=hf_embed, persist_directory=vector_db_path)\n",
    "    return db.similarity_search(question, k=similar_doc_count)\n",
    "\n",
    "\n",
    "def build_qa_chain():\n",
    "    model_name = \"databricks/dolly-v2-7b\" # can use dolly-v2-3b or dolly-v2-7b for smaller model and faster inferences.\n",
    "\n",
    "    instruct_pipeline = pipeline(model=model_name, torch_dtype=torch.bfloat16, trust_remote_code=True,\n",
    "                                device_map=\"auto\",return_full_text=True, max_new_tokens=256, \n",
    "                                top_p=0.95, top_k=50)\n",
    "\n",
    "    # Note: if you use dolly 12B or smaller model but a GPU with less than 24GB RAM, use 8bit. This requires %pip install bitsandbytes\n",
    "    #   instruct_pipeline = pipeline(model = model_name, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"auto\", model_kwargs={'load_in_8bit': True})\n",
    "    # For GPUs without bfloat16 support, like the T4 or V100, use torch_dtype=torch.float16 below\n",
    "    # model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True)\n",
    "\n",
    "    template = \"\"\"\n",
    "            I will ask you questions based on the following context:\n",
    "            — Start of Context —\n",
    "            {context}\n",
    "            — End of Context—\n",
    "            Use the information in the above paragraphs only to answer the question at the end. If the answer is not given in the context, say that \"I do not know\".\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Response:\n",
    "            \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(input_variables=['context', 'question'], template=template)\n",
    "\n",
    "    hf_pipe = HuggingFacePipeline(pipeline=instruct_pipeline)\n",
    "    # Set verbose=True to see the full prompt:\n",
    "    return load_qa_chain(llm=hf_pipe, chain_type=\"stuff\", prompt=prompt, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "async def homepage(request):\n",
    "    \"\"\"Handle the homepage request and return a JSON response.\n",
    "    Args:\n",
    "        request: The incoming request object.\n",
    "    Returns:\n",
    "        JSONResponse: The JSON response containing the output.\n",
    "    \"\"\"\n",
    "    payload = await request.body()\n",
    "    string = payload.decode(\"utf-8\")\n",
    "    # similar_docs = get_similar_docs(string, similar_doc_count=2)\n",
    "    response_q = asyncio.Queue()\n",
    "    await request.app.model_queue.put((string, response_q))\n",
    "    output = await response_q.get()\n",
    "    return JSONResponse(output)\n",
    "\n",
    "\n",
    "async def check_file_changes():\n",
    "    \n",
    "    directory = PDF_DIRECTORY  # Specify the directory to monitor for file changes\n",
    "    file_set = set()\n",
    "\n",
    "    while True:\n",
    "        new_files = set(os.listdir(directory)) - file_set\n",
    "        if new_files:\n",
    "            # Perform any notification or action for the new files\n",
    "            print(\"New file(s) uploaded:\", new_files)\n",
    "            pdf_path = PDF_DIRECTORY + \"/\" + list(new_files)[0]\n",
    "            print(pdf_path)\n",
    "            file_path = PDF_DIRECTORY + \"/\" + list(new_files)[0]\n",
    "            file_type = magic.from_file(file_path, mime=True)\n",
    "            doc = None  # Initialize doc variable before assignment\n",
    "\n",
    "            if file_type == 'application/pdf':\n",
    "                # Process the PDF file\n",
    "                doc = parse_pdf(file_path)\n",
    "            elif file_type in ['audio/mp3', 'audio/wav','audio/mpeg', 'video/mp4']:\n",
    "                # Process the audio file\n",
    "                doc = multimedia_to_text(file_path)\n",
    "            else:\n",
    "                print(\"Unsupported file type:\", file_type)\n",
    "                # Add any necessary actions for unsupported file types\n",
    "\n",
    "            # Clear out the path ./vector_db/\n",
    "            clear_path = vector_db_path\n",
    "            clear_files(clear_path)  # Implement a function to clear out the specified path\n",
    "            if doc is not None:\n",
    "                pages = text_to_docs(doc)\n",
    "                # print(pages)\n",
    "                create_embed(pages)\n",
    "                print(\"************************---------- Created Embeddings ----------*************************\")   \n",
    "            else:     \n",
    "                print(\" ^^^^^^^^^^^^^^^^^^^^^^^^^^ No doc created ^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "        file_set = set(os.listdir(directory))\n",
    "        await asyncio.sleep(1)  # Adjust the time interval between checks as needed\n",
    "\n",
    "async def server_loop(q):\n",
    "    \"\"\"Process incoming requests from a queue in a loop and generate responses.\n",
    "    Args:\n",
    "        q: The input queue containing requests.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    qa_chain = build_qa_chain()\n",
    "    while True:\n",
    "        \n",
    "        (string, response_q) = await q.get()\n",
    "        similar_docs = get_similar_docs(string, similar_doc_count=2)\n",
    "        # Convert Document objects to dictionaries\n",
    "        similar_docs_serializable = []\n",
    "        for doc in similar_docs:\n",
    "            doc_serializable = {\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            }\n",
    "            similar_docs_serializable.append(doc_serializable)\n",
    "        out = qa_chain({\"input_documents\": similar_docs, \"question\": string})\n",
    "\n",
    "        res = {\n",
    "            \"similar_docs\": similar_docs_serializable,\n",
    "            \"output_text\": out['output_text']\n",
    "        }\n",
    "\n",
    "        await response_q.put(res)\n",
    "\n",
    "def startup():\n",
    "    q = asyncio.Queue()\n",
    "    app.model_queue = q\n",
    "    asyncio.create_task(server_loop(q))\n",
    "    # asyncio.create_task(check_pdf_upload())  # Start the PDF upload checking task\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.create_task(check_file_changes())\n",
    "    # loop.run_until_complete(app.run())\n",
    "\n",
    "\n",
    "app = Starlette(\n",
    "    routes=[\n",
    "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
    "    ],\n",
    "    on_startup=[startup]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7fa9d3c-d337-4c7c-89ca-a6ec2d1a0b9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# Run the server\n",
    "cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "workspace_url = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "org_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")\n",
    "endpoint_url = f\"https://{workspace_url}/driver-proxy-api/o/{org_id}/{cluster_id}/7777/\"\n",
    "print(f\"Access this API at {endpoint_url}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "!uvicorn --host 0.0.0.0 --port 7777 server:app"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cleaned",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
